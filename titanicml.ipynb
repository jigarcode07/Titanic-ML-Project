{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4384e1-ffcc-4666-bed1-dacf6e5e10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa5be2d-eddc-42ba-a06b-5103671b108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8156424581005587\n",
      "[[90 15]\n",
      " [18 56]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.86      0.85       105\n",
      "         1.0       0.79      0.76      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.81      0.81      0.81       179\n",
      "weighted avg       0.81      0.82      0.82       179\n",
      "\n",
      "Cross-validation Accuracy: 0.8283 ± 0.0229\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "# Titanic Survival Prediction - Advanced Pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load Data\n",
    "train = pd.read_csv(r'C:\\Users\\HP\\Downloads\\train.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\HP\\Downloads\\test (1).csv')\n",
    "test_passenger_ids = test['PassengerId']\n",
    "\n",
    "# Combine train & test for uniform preprocessing\n",
    "data = pd.concat([train, test], sort=False)\n",
    "\n",
    "# Feature Engineering\n",
    "# Extract Title\n",
    "data['Title'] = data['Name'].str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "data['Title'] = data['Title'].replace(['Mlle', 'Ms'], 'Miss')\n",
    "data['Title'] = data['Title'].replace(['Mme'], 'Mrs')\n",
    "data['Title'] = data['Title'].replace(['Capt', 'Col', 'Major', 'Dr', 'Rev', 'Jonkheer', 'Don', 'Sir', 'the Countess', 'Lady', 'Dona'], 'Rare')\n",
    "\n",
    "# Fill missing Age based on Title median\n",
    "data['Age'] = data.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill missing Embarked with mode\n",
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])\n",
    "\n",
    "# Fill missing Fare with median\n",
    "data['Fare'] = data['Fare'].fillna(data['Fare'].median())\n",
    "\n",
    "# Cabin Feature: Missing or Not\n",
    "data['CabinKnown'] = data['Cabin'].notnull().astype(int)\n",
    "\n",
    "# Family size\n",
    "data['FamilySize'] = data['SibSp'] + data['Parch'] + 1\n",
    "data['IsAlone'] = (data['FamilySize'] == 1).astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_cols = ['Sex', 'Embarked', 'Title']\n",
    "le = LabelEncoder()\n",
    "for col in label_cols:\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "\n",
    "# Drop unneeded columns\n",
    "drop_cols = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "data.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "# Split back into train and test\n",
    "train_cleaned = data[:len(train)]\n",
    "test_cleaned = data[len(train):]\n",
    "X = train_cleaned.drop(columns='Survived')\n",
    "y = train_cleaned['Survived']\n",
    "X_test = test_cleaned.drop(columns='Survived')\n",
    "\n",
    "# Feature Scaling (important for some models)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Split training data for local validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model: XGBoost (high performance)\n",
    "model = xgb.XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation\n",
    "y_pred_val = model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "print(\"Cross-validation Accuracy: %.4f ± %.4f\" % (cv_scores.mean(), cv_scores.std()))\n",
    "\n",
    "# Predict on test set\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f9ac9-570d-4ee2-b58e-c7eb631c631e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
